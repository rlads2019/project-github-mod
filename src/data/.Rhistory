results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'.csv'))
comment_tmp <- data.frame()
try(for (r in 1:length(comments)){
comment <- rbind(comments[[r]], comment_tmp)
})
write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
comments
comment_temp
# a loop to get comments
for(j in 11:11){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'.csv'))
comment_tmp <- data.frame()
try(for (r in 1:length(comments)){
comment <- rbind(comments[[r]], comment_tmp)
})
write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
yt_oauth('1082375075040-rsm8kit4fra0q3ro0evaba91v02mo2lp.apps.googleusercontent.com
', 'RRsHNtzjgw5uNPl-nYCVa7E9', token = '')
yt_oauth('1082375075040-rsm8kit4fra0q3ro0evaba91v02mo2lp.apps.googleusercontent.com', 'RRsHNtzjgw5uNPl-nYCVa7E9', token = '')
# a loop to get comments
for(j in 12:50){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'.csv'))
#comment_tmp <- data.frame()
#try(for (r in 1:length(comments)){
#comment <- rbind(comments[[r]], comment_tmp)
#})
#write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
# a loop to get comments
for(j in 25:50){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'.csv'))
#comment_tmp <- data.frame()
#try(for (r in 1:length(comments)){
#comment <- rbind(comments[[r]], comment_tmp)
#})
#write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
# a loop to get comments
for(j in 51:51){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'.csv'))
#comment_tmp <- data.frame()
#try(for (r in 1:length(comments)){
#comment <- rbind(comments[[r]], comment_tmp)
#})
#write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
# a loop to get comments
for(j in 52:60){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'.csv'))
#comment_tmp <- data.frame()
#try(for (r in 1:length(comments)){
#comment <- rbind(comments[[r]], comment_tmp)
#})
#write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
# a loop to get comments
for(j in 61:61){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'.csv'))
#comment_tmp <- data.frame()
#try(for (r in 1:length(comments)){
#comment <- rbind(comments[[r]], comment_tmp)
#})
#write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
# a loop to get comments
for(j in 62:70){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'.csv'))
#comment_tmp <- data.frame()
#try(for (r in 1:length(comments)){
#comment <- rbind(comments[[r]], comment_tmp)
#})
#write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
# a loop to get comments
for(j in 71:100){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'.csv'))
#comment_tmp <- data.frame()
#try(for (r in 1:length(comments)){
#comment <- rbind(comments[[r]], comment_tmp)
#})
#write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
# a loop to get comments
for(j in 1:5){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/Global/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/Global/comments_data/', as.character(j) ,'.csv'))
#comment_tmp <- data.frame()
#try(for (r in 1:length(comments)){
#comment <- rbind(comments[[r]], comment_tmp)
#})
#write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
# a loop to get comments
for(j in 6:30){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/Global/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/Global/comments_data/', as.character(j) ,'.csv'))
#comment_tmp <- data.frame()
#try(for (r in 1:length(comments)){
#comment <- rbind(comments[[r]], comment_tmp)
#})
#write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
# a loop to get comments
for(j in 31:100){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/Global/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/Global/comments_data/', as.character(j) ,'.csv'))
#comment_tmp <- data.frame()
#try(for (r in 1:length(comments)){
#comment <- rbind(comments[[r]], comment_tmp)
#})
#write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
yt_search('')
yt_oauth('1066293950203-c9e2htndrkf8ftjd17mfdahi7j8o1k1j.apps.googleusercontent.com', '2MvRusGQ0t8daTcxVH59fA0N', token = '')
# a loop to get comments
for(j in 64:100){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/Global/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/Global/comments_data/', as.character(j) ,'.csv'))
#comment_tmp <- data.frame()
#try(for (r in 1:length(comments)){
#comment <- rbind(comments[[r]], comment_tmp)
#})
#write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
yt_search('')
# a loop to get comments
for(j in 65:100){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/Global/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/Global/comments_data/', as.character(j) ,'.csv'))
#comment_tmp <- data.frame()
#try(for (r in 1:length(comments)){
#comment <- rbind(comments[[r]], comment_tmp)
#})
#write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
# a loop to get comments
for(j in 66:100){
channel_videos <- read.csv(paste0("~/Documents/GitHub/R-Final-Project/R-Final-Project/data/Global/", as.character(j), '.csv'))
results <- tibble(video_id = character(), comments_count = numeric(), reply_rate = numeric())
comments <- list()
for (i in 1:dim(channel_videos)[1]){
# record the comments count
video_id <- as.character(channel_videos$id[i])
comments_count <- as.numeric(channel_videos$commentCount[i])
try(comments[[i]] <- get_all_comments(video_id), silent = T)
try(replied_comments <- comments[[i]] %>%
# filter the ones that were replied
filter(!is.na(parentId)) %>%
# filter the ones that were replied by the YouTuber 可能要分頻道慢慢爬...
#filter(authorChannelId.value == "UCG-KntY7aVnIGXYEBQvmBAQ")
filter(authorChannelId.value == as.character(taiwan_growth_channel_ids[j,1])), silent = T)
# save the reply rate
try(reply_rate <- dim(replied_comments)[1]/comments_count, silent = T)
results[i, 1] <- video_id
results[i, 2] <- comments_count
try(if(reply_rate != Inf){
results[i, 3] <- reply_rate
}else{
results[i, 3] <- -1
}, silent = T)
print(c(j,i,'completed!'))
}
#Stats: 1 daily token can scrape kind of 4 channels (22XX data for Channel "Tom Frankly")
write.csv(results, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/Global/comments_data/', as.character(j) ,'.csv'))
#comment_tmp <- data.frame()
#try(for (r in 1:length(comments)){
#comment <- rbind(comments[[r]], comment_tmp)
#})
#write.csv(comment_temp, paste0('~/Documents/GitHub/R-Final-Project/R-Final-Project/data/tw/all_channel_video_stats/comments_data/', as.character(j) ,'_comments.csv'))
}
